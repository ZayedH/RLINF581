{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './utils')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from game import *\n",
    "from tools import *\n",
    "from tqdm import trange, tqdm\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play one against the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [\"Ace\", \"King\", \"Queen\", \"Jack\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "signs = [\"Club\", \"Diamond\", \"Heart\", \"Spade\"]\n",
    "initialW = 100\n",
    "n = 7\n",
    "m = 11\n",
    "it = int(5*1e3)\n",
    "lr = .5\n",
    "exp = .3\n",
    "step = 1e-5\n",
    "alpha = 3.\n",
    "decay = 1.\n",
    "maxBet = 10\n",
    "retreat = 1\n",
    "parameters = np.ones((2*(m-n)+1, maxBet, 2))*1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(): \n",
    "    \n",
    "    def __init__(self, firstPlayer, secondPlayer):\n",
    "        self.cards = 4*list(range(n, m+1))\n",
    "        self.firstPlayer = firstPlayer\n",
    "        self.secondPlayer = secondPlayer\n",
    "        self.turn = random.randint(0, 1)\n",
    "        \n",
    "    def deal(self):\n",
    "        random.shuffle(self.cards)\n",
    "        self.turn = 1 - self.turn\n",
    "        self.firstPlayer.hand = [self.cards[0], self.cards[2]]\n",
    "        self.firstPlayer.sum = sum(self.firstPlayer.hand)\n",
    "        self.secondPlayer.hand = [self.cards[1], self.cards[3]]\n",
    "        self.secondPlayer.sum = sum(self.secondPlayer.hand)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.secondPlayer.reset()\n",
    "        self.firstPlayer.reset()\n",
    "        self.turn = random.randint(0, 1)\n",
    "        \n",
    "    def learn(self, rounds = 10):\n",
    "\n",
    "        score = 0\n",
    "        for _ in range(rounds):\n",
    "            self.reset()\n",
    "            while self.firstPlayer.worth * self.secondPlayer.worth > 0:\n",
    "                self.deal()\n",
    "                play(self.firstPlayer, self.secondPlayer, self.turn)\n",
    "            score += (self.firstPlayer.worth > 0)\n",
    "            \n",
    "        return score\n",
    "    \n",
    "    def human(self, results = True):\n",
    "\n",
    "        self.reset()\n",
    "        while self.firstPlayer.worth * self.secondPlayer.worth > 0:\n",
    "            self.deal()\n",
    "            play(self.firstPlayer, self.secondPlayer, self.turn)\n",
    "            \n",
    "            if results:\n",
    "                print(\"-------------------------\")\n",
    "                print(\"The {0} hand and last action were: {1}-{2}\".format(self.secondPlayer.name, self.secondPlayer.hand, self.secondPlayer.action))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"The {0} hand and last action were: {1}-{2}\".format(self.firstPlayer.name, self.firstPlayer.hand, self.firstPlayer.action))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"Current Net Worth of {0}: {1} - Current Net Worth of {2}: {3}\".format(self.firstPlayer.name, self.firstPlayer.worth, self.secondPlayer.name, self.secondPlayer.worth))\n",
    "                print(\"=========================\")\n",
    "            \n",
    "        if self.secondPlayer.worth > 0:\n",
    "            print(\"\\n And the final winner is {0}! :)\".format(self.secondPlayer.name))\n",
    "        else:\n",
    "            print(\"\\n And the final winner is {0}! :>\".format(self.firstPlayer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    \n",
    "    def __init__(self, name = \"Player\", lr = lr, exp = exp):\n",
    "        self.trainable = True\n",
    "        self.worth = initialW\n",
    "        self.statDict = {}\n",
    "        self.lr = lr\n",
    "        self.exp = exp\n",
    "        self.name = name\n",
    "        self.maxBet = maxBet\n",
    "        \n",
    "    def reset(self):\n",
    "        self.worth = initialW\n",
    "        \n",
    "    def chooseAction(self, actions, advAction):\n",
    "        state = str(self.sum) + \"-\" + str(advAction) + \"-\" + str(self.lastAction)\n",
    "        if random.random() < self.exp or self.statDict.get(state) is None:\n",
    "            return random.choice(actions)\n",
    "        action = int(max(self.statDict.get(state), key = lambda x: self.statDict.get(state)[x]))\n",
    "        return action\n",
    "        \n",
    "    def update(self, adverser, boolean):\n",
    "        if self.trainable:\n",
    "            if adverser.action > 0:\n",
    "                if boolean:\n",
    "                    state = str(self.sum) + \"-\" + str(None) + \"-\" + str(self.lastAction)\n",
    "                else:\n",
    "                    state = str(self.sum) + \"-\" + str(adverser.action) + \"-\" + str(self.lastAction)\n",
    "                \n",
    "                if self.statDict.get(state) is None:\n",
    "                    self.statDict[state] = {}\n",
    "                if self.statDict.get(state).get(str(self.action)) is None:\n",
    "                    self.statDict[state][str(self.action)] = 0\n",
    "\n",
    "                if self.action == adverser.action:\n",
    "                    if self.sum > adverser.sum:\n",
    "                        self.statDict[state][str(self.action)] += self.lr*(  self.action - self.statDict[state][str(self.action)])\n",
    "                    elif self.sum < adverser.sum:\n",
    "                        self.worth -= self.action\n",
    "                        self.statDict[state][str(self.action)] += self.lr*(- self.action - self.statDict[state][str(self.action)])\n",
    "\n",
    "                elif self.action == 0:\n",
    "                    if self.lastAction is None:\n",
    "                        self.worth -= retreat\n",
    "                        self.statDict[state][str(self.action)] += self.lr*(- retreat - self.statDict[state][str(self.action)])\n",
    "\n",
    "                    else:\n",
    "                        self.worth -= self.lastAction\n",
    "                        self.statDict[state][str(self.action)] += self.lr*(- self.lastAction - self.statDict[state][str(self.action)])\n",
    "        \n",
    "        else:\n",
    "            if self.action == adverser.action and self.sum < adverser.sum:\n",
    "                self.worth -= self.action\n",
    "            elif self.action == 0:\n",
    "                if self.lastAction is None:\n",
    "                    self.worth -= retreat\n",
    "                else:\n",
    "                    self.worth -= self.lastAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer(Player):\n",
    "    \n",
    "    def __init__(self, name = \"HumanPlayer\"):\n",
    "        Player.__init__(self)\n",
    "        self.name = name\n",
    "        \n",
    "    def chooseAction(self, actions, advAction):\n",
    "        print(\"State: \", self.hand)\n",
    "        \n",
    "        if advAction is None: \n",
    "            pass\n",
    "        else:\n",
    "            print(\"Adverser played: \", advAction)\n",
    "            \n",
    "        action = int(input(\"Input your action: \")) \n",
    "        \n",
    "        while action not in actions:\n",
    "            print(\"Try a number in \", actions)\n",
    "            action = int(input(\"Input your action: \"))  \n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def update(self, adverser, boolean):\n",
    "        if self.action == adverser.action and self.sum < adverser.sum:\n",
    "            self.worth -= self.action\n",
    "        elif self.action == 0:\n",
    "            if self.lastAction is None:\n",
    "                self.worth -= retreat\n",
    "            else:\n",
    "                self.worth -= self.lastAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO TRAIN A BASIC SIMPLE MODEL YOU CAN USE, IT IS NOT VERY SMART\n",
    "# firstPlayer = Player()\n",
    "# secondPlayer = Player()\n",
    "# cards = Cards(firstPlayer, secondPlayer)\n",
    "# cards.train(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TO PLAY AGAINST A VIRTUAL PLAYER, YOU CAN UNCOMMENT THE FOLLOWING LINES AFTER TRAINING THE AGENT\n",
    "# firstPlayer.reset()\n",
    "# human = HumanPlayer()\n",
    "# cards = Cards(firstPlayer, human)\n",
    "# cards.human()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPlayer(Player):\n",
    "    \n",
    "    def __init__(self, name = \"GreedyPlayer\"):\n",
    "        Player.__init__(self)\n",
    "        self.name = name\n",
    "        \n",
    "    def chooseAction(self, actions, advAction):\n",
    "        if advAction is None:\n",
    "            return random.choice(actions[:int(self.sum*maxBet/(2*m))])\n",
    "        if self.sum > m + n:\n",
    "            return advAction\n",
    "        return 0\n",
    "    \n",
    "    def update(self, adverser, boolean):\n",
    "        if self.action == adverser.action and self.sum < adverser.sum:\n",
    "            self.worth -= self.action\n",
    "        elif self.action == 0:\n",
    "            if self.lastAction is None:\n",
    "                self.worth -= retreat\n",
    "            else:\n",
    "                self.worth -= self.lastAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO TRAIN A BASIC SIMPLE MODEL YOU CAN USE, IT IS NOT VERY SMART\n",
    "# firstPlayer = GreedyPlayer()\n",
    "# secondPlayer = Player()\n",
    "# cards = Cards(firstPlayer, secondPlayer)\n",
    "# cards.train(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TO PLAY AGAINST A VIRTUAL PLAYER, YOU CAN UNCOMMENT THE FOLLOWING LINES AFTER TRAINING THE AGENT\n",
    "# human = HumanPlayer()\n",
    "# cards = Cards(firstPlayer, human)\n",
    "# cards.human()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# À refaire\n",
    "\"\"\"\n",
    "class ThompsonSampling(Player):\n",
    "    def __init__(self, parameters = parameters, name = \"Thompson\", exp = exp):\n",
    "        Player.__init__(self)\n",
    "        self.exp = exp\n",
    "        self.step = step\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        self.nbDraws = np.zeros((2*(m-n) + 1, maxBet + 1))\n",
    "        self.cumRewards = np.zeros((2*(m-n) + 1, maxBet + 1))\n",
    "\n",
    "    def chooseAction(self, actions, advAction):\n",
    "        if advAction is None:\n",
    "            expression = np.zeros(maxBet + 1)\n",
    "            for i in range(len(actions)):\n",
    "                act = actions[i]\n",
    "                expression[act] = np.random.beta(self.parameters[self.sum - 2*n, act - 1, 0] + self.cumRewards[self.sum-2*n, act],\n",
    "                                             self.parameters[self.sum - 2*n, act - 1, 1] + self.nbDraws[self.sum-2*n, act] - self.cumRewards[self.sum-2*n, act])\n",
    "            return random.choice(actions)\n",
    "        elif random.random() < self.exp:\n",
    "            return random.choice(actions)\n",
    "        \n",
    "        action = advAction\n",
    "        expression = np.zeros(maxBet + 1)\n",
    "        for i in range(len(actions)):\n",
    "            act = actions[i]\n",
    "            expression[act] = np.random.beta(self.parameters[self.sum - 2*n, action - 1, 0] + self.cumRewards[self.sum-2*n, act],\n",
    "                                             self.parameters[self.sum - 2*n, action - 1, 1] + self.nbDraws[self.sum-2*n, act] - self.cumRewards[self.sum-2*n, act])\n",
    "        return randmax(expression)\n",
    "        \n",
    "    def update(self, adverser, boolean):\n",
    "        if self.trainable:\n",
    "            if self.action == adverser.action:\n",
    "                if self.sum > adverser.sum:\n",
    "                    self.parameters[self.sum - 2*n, adverser.action - 1, 0] += self.step\n",
    "                elif self.sum < adverser.sum:\n",
    "                    self.worth -= adverser.action\n",
    "                    self.parameters[self.sum - 2*n, adverser.action - 1, 1] += self.step\n",
    "                    \n",
    "            elif self.action == 0:\n",
    "                if self.lastAction is None:\n",
    "                    self.worth -= retreat\n",
    "                else:\n",
    "                    self.worth -= self.lastAction\n",
    "                    self.parameters[self.sum - 2*n, adverser.action - 1, 1] += self.step\n",
    "            \n",
    "        else:\n",
    "            if self.action == adverser.action and self.sum < adverser.sum:\n",
    "                self.worth -= self.action\n",
    "            elif self.action == 0:\n",
    "                if self.lastAction is None:\n",
    "                    self.worth -= retreat\n",
    "                else:\n",
    "                    self.worth -= self.lastAction\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstPlayer = ThompsonSampling()\n",
    "# secondPlayer = Player()\n",
    "# cards = Cards(firstPlayer, secondPlayer)\n",
    "# cards.train(it, bandit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cards = Cards(firstPlayer, HumanPlayer())\n",
    "# cards.human(human = True, bandit = True, result = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# À refaire\n",
    "\"\"\"\n",
    "class UCBSampling(Player):\n",
    "    def __init__(self, alpha = alpha, name = \"UCB\", exp = exp):\n",
    "        Player.__init__(self)\n",
    "        self.exp = exp\n",
    "        self.name = name\n",
    "        self.alpha = alpha\n",
    "        self.nbDraws = np.zeros((2*(m-n) + 1, maxBet + 1))\n",
    "        self.cumRewards = np.zeros((2*(m-n) + 1, maxBet + 1))\n",
    "\n",
    "    def chooseAction(self, actions, advAction):\n",
    "        \n",
    "        if random.random() < self.exp:\n",
    "            final = random.choice(actions)\n",
    "            self.cumRewards[self.sum-2*n, final] += 1\n",
    "            return final\n",
    "        \n",
    "        expression = np.zeros(maxBet + 1)\n",
    "        calls = np.sum(self.nbDraws)\n",
    "        \n",
    "        for i in range(len(actions)):\n",
    "            act = actions[i]\n",
    "            if self.nbDraws[self.sum-2*n, act] < 1: expression[act] = np.inf\n",
    "            else:\n",
    "                expression[act] = self.cumRewards[self.sum-2*n, act]/self.nbDraws[self.sum-2*n, act] + np.sqrt((self.alpha*np.log(calls+1))/self.nbDraws[self.sum-2*n, act])\n",
    "        \n",
    "        final = randmax(expression)\n",
    "        self.cumRewards[self.sum-2*n, final] += 1\n",
    "        return final\n",
    "        \n",
    "    def update(self, adverser, boolean): \n",
    "        if self.trainable:\n",
    "            if self.action == adverser.action:\n",
    "                if self.sum > adverser.sum:\n",
    "                    self.cumRewards[self.sum-2*n, adverser.action] += adverser.action\n",
    "                elif self.sum < adverser.sum:\n",
    "                    self.worth -= adverser.action\n",
    "                    self.cumRewards[self.sum-2*n, adverser.action] -= adverser.action\n",
    "            elif self.action == 0:\n",
    "                if self.lastAction is None:\n",
    "                    self.worth -= retreat\n",
    "                else:\n",
    "                    self.worth -= self.lastAction\n",
    "                self.cumRewards[self.sum-2*n, adverser.action] -= adverser.action\n",
    "        else:\n",
    "            if self.action == adverser.action and self.sum < adverser.sum:\n",
    "                self.worth -= adverser.action\n",
    "            elif self.action == 0:\n",
    "                if self.lastAction is None:\n",
    "                    self.worth -= retreat\n",
    "                else:\n",
    "                    self.worth -= self.lastAction\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstPlayer = UCB()\n",
    "# secondPlayer = Player()\n",
    "# cards = Cards(firstPlayer, secondPlayer)\n",
    "# cards.train(it, bandit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards = Cards(firstPlayer, HumanPlayer())\n",
    "# cards.human(human = True, bandit = True, result = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who's better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3003"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstPlayer = Player(lr = .1)\n",
    "secondPlayer = Player(lr = .9)\n",
    "game = Game(firstPlayer, secondPlayer)\n",
    "game.learn(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedyPlayer = GreedyPlayer()\n",
    "game = Game(firstPlayer, greedyPlayer)\n",
    "game.learn(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▏                     | 48/100 [03:06<03:23,  3.91s/it]"
     ]
    }
   ],
   "source": [
    "learning = []\n",
    "batch = 5000\n",
    "secondPlayer.trainable = False\n",
    "\n",
    "for i in trange(100):\n",
    "    game = Game(firstPlayer, secondPlayer)\n",
    "    learning.append(game.learn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = smooth(learning, 10)\n",
    "plt.plot(learning)\n",
    "plt.plot(x, y)\n",
    "plt.plot(np.ones(len(learning))*batch//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPlayer.statDict.get(\"21-None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who's better Zayed or the computer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# game = Game(GreedyPlayer(), HumanPlayer())\n",
    "# game.human(results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
