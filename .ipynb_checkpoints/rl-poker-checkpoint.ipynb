{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play one against the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [\"Ace\", \"King\", \"Queen\", \"Jack\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "signs = [\"Club\", \"Diamond\", \"Heart\", \"Spade\"]\n",
    "initialW = 100\n",
    "n = 7\n",
    "m = 11\n",
    "it = int(5*1e4)\n",
    "lr = .2\n",
    "exp = .4\n",
    "decay = 1.\n",
    "maxBet = 10\n",
    "parameters = [[1, 1] for i in range(maxBet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cards: \n",
    "    \n",
    "    def __init__(self, firstPlayer, secondPlayer):\n",
    "        \"\"\"Define the deck of cards\"\"\"\n",
    "        self.cards = 4*list(range(n, m+1))\n",
    "        self.firstPlayer = firstPlayer\n",
    "        self.secondPlayer = secondPlayer\n",
    "        self.turn = random.randint(0, 1)\n",
    "        \n",
    "    def deal(self):\n",
    "        \"\"\"Distribution of cards by the agent :)\"\"\"\n",
    "        random.shuffle(self.cards)\n",
    "        self.turn = 1 - self.turn\n",
    "        self.firstPlayer.hand = [self.cards[0], self.cards[2]]\n",
    "        self.secondPlayer.hand = [self.cards[1], self.cards[3]]\n",
    "        \n",
    "    def restart(self):\n",
    "        self.secondPlayer.reset()\n",
    "        self.firstPlayer.reset()\n",
    "        self.turn = random.randint(0, 1)\n",
    "        \n",
    "    def reward(self, first, f, second, s, Thompson, tTurn):\n",
    "        \n",
    "        if first.action == second.action and sum(first.hand) > sum(second.hand):\n",
    "            second.worth -= second.action\n",
    "            st = str(first.hand) + \"-\" + str(second.action)\n",
    "            \n",
    "            if Thompson and not tTurn:\n",
    "                first.update(st, first.action)\n",
    "                second.update(second.hand, first.hand, first.action)\n",
    "            \n",
    "            elif Thompson and tTurn:\n",
    "                first.update(first.hand, second.hand, second.action)\n",
    "                \n",
    "            else:\n",
    "                first.update(st, first.action)\n",
    "            \n",
    "        elif first.action == second.action and sum(first.hand) < sum(second.hand):\n",
    "            first.worth -= first.action\n",
    "            st = str(second.hand) + \"-\" + str(first.action)\n",
    "            \n",
    "            if Thompson and not tTurn:\n",
    "                second.update(second.hand, first.hand, first.action)\n",
    "            \n",
    "            elif Thompson and tTurn:\n",
    "                first.update(first.hand, second.hand, second.action)\n",
    "                second.update(st, first.action)\n",
    "            else:\n",
    "                second.update(st, first.action)\n",
    "            \n",
    "            \n",
    "        elif second.action == 0:\n",
    "            second.worth -= s\n",
    "            \n",
    "        elif first.action == 0:\n",
    "            first.worth -= f\n",
    "            \n",
    "    def play(self, first, second, human = False, Thompson = False, tTurn = 1):\n",
    "        \n",
    "        beforeFirstAction = 1\n",
    "        actions = list(range(1, min(maxBet, first.worth, second.worth)+1))\n",
    "        \n",
    "        if human:\n",
    "            first.action = first.chooseAction(actions, str(first.hand))\n",
    "        else:\n",
    "            first.action = first.chooseAction(actions, None)\n",
    "            \n",
    "        beforeSecondAction = 1\n",
    "        actions = list(range(first.action, min(maxBet, first.worth, second.worth)+1))\n",
    "        actions.append(0)\n",
    "        second.action = second.chooseAction(actions, str(second.hand) +\"-\"+ str(first.action))\n",
    "\n",
    "        while first.action*second.action > 0 and first.action != second.action:\n",
    "            \n",
    "            beforeFirstAction = first.action\n",
    "            actions = list(range(second.action , min(maxBet, first.worth, second.worth)+1))\n",
    "            actions.append(0)\n",
    "            first.action = first.chooseAction(actions, str(first.hand) +\"-\"+ str(second.action))\n",
    "            \n",
    "            if first.action > 0 and second.action != first.action:\n",
    "                \n",
    "                beforeSecondAction = second.action\n",
    "                actions = list(range(first.action, min(maxBet, first.worth, second.worth)+1))\n",
    "                actions.append(0)\n",
    "                second.action = second.chooseAction(actions, str(second.hand) +\"-\"+ str(first.action))\n",
    "\n",
    "        self.reward(first, beforeFirstAction, second, beforeSecondAction, Thompson, tTurn)\n",
    "\n",
    "    def train(self, rounds = 10, Thompson = False):\n",
    "\n",
    "        score = 0\n",
    "        for _ in range(rounds):\n",
    "            self.restart()\n",
    "            while self.firstPlayer.worth * self.secondPlayer.worth > 0:\n",
    "                self.deal()\n",
    "                if self.turn:\n",
    "                    self.play(self.firstPlayer, self.secondPlayer, Thompson = Thompson, tTurn = self.turn)\n",
    "                else:\n",
    "                    self.play(self.secondPlayer, self.firstPlayer, Thompson = Thompson, tTurn = self.turn)\n",
    "            score += (self.firstPlayer.worth > 0) - (self.secondPlayer.worth > 0)\n",
    "            \n",
    "        return score\n",
    "    \n",
    "    def human(self, human = False, Thompson = False, result = False):\n",
    "\n",
    "        self.restart()\n",
    "        while self.firstPlayer.worth * self.secondPlayer.worth > 0:\n",
    "            self.deal()\n",
    "            if self.turn:\n",
    "                self.play(self.firstPlayer, self.secondPlayer, Thompson = Thompson, tTurn = self.turn)\n",
    "            else:\n",
    "                self.play(self.secondPlayer, self.firstPlayer, human, Thompson = Thompson, tTurn = self.turn)\n",
    "            \n",
    "            if result:\n",
    "                print(\"-------------------------\")\n",
    "                print(\"The agent hand and last action were: {0} {1}\".format(self.secondPlayer.hand, self.secondPlayer.action))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"The adversary hand and last action were: {0} {1}\".format(self.firstPlayer.hand, self.firstPlayer.action))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"Current Net Worth: {0}-{1}\".format(self.firstPlayer.worth, self.secondPlayer.worth))\n",
    "                print(\"=========================\")\n",
    "            \n",
    "        if self.secondPlayer.worth > 0:\n",
    "            print(\"\\n And the final winner is secondPlayer! :)\")\n",
    "        else:\n",
    "            print(\"\\n And the final winner is firstPlayer! :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    \n",
    "    def __init__(self, human = False):\n",
    "        self.worth = initialW\n",
    "        self.statDict = {}\n",
    "        \n",
    "    def reset(self):\n",
    "        self.worth = initialW\n",
    "        \n",
    "    def chooseAction(self, actions, state):\n",
    "        \n",
    "        if state is None:\n",
    "            return random.choice(actions)\n",
    "        \n",
    "        elif random.random() < exp:\n",
    "            return random.choice(actions)\n",
    "\n",
    "        action = None\n",
    "        vmax = - 1e10\n",
    "        for act in actions:\n",
    "            current = 0 if self.statDict.get(state) is None or self.statDict.get(state).get(str(act)) is None else self.statDict.get(state).get(str(act))\n",
    "            if vmax < current:\n",
    "                vmax = current\n",
    "                action = act\n",
    "                    \n",
    "            return action\n",
    "        \n",
    "    def update(self, state, action):\n",
    "        if self.statDict.get(state) is None:\n",
    "            self.statDict[state] = {}\n",
    "        if self.statDict.get(state).get(str(action)) is None:\n",
    "            self.statDict[state][str(action)] = 0\n",
    "        self.statDict[state][str(action)] += lr*(action - self.statDict[state][str(action)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer(Player):\n",
    "        \n",
    "    def chooseAction(self, actions, state):\n",
    "        print(\"State: \", state)\n",
    "        action = int(input(\"Input your action: \")) \n",
    "        \n",
    "        while action not in actions:\n",
    "            print(\"Try a number in \", actions)\n",
    "            action = int(input(\"Input your action: \"))  \n",
    "            \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO TRAIN A BASIC SIMPLE MODEL YOU CAN USE, IT IS NOT VERY SMART\n",
    "# firstPlayer = Player()\n",
    "# secondPlayer = Player()\n",
    "# cards = Cards(firstPlayer, secondPlayer)\n",
    "# cards.train(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TO PLAY AGAINST A VIRTUAL PLAYER, YOU CAN UNCOMMENT THE FOLLOWING LINES AFTER TRAINING THE AGENT\n",
    "# firstPlayer.reset()\n",
    "# human = HumanPlayer()\n",
    "# cards = Cards(firstPlayer, human)\n",
    "# cards.human()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThompsonSampling(Player):\n",
    "    def __init__(self, parameters = parameters):\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def chooseAction(self, actions, state):\n",
    "        if state is None:\n",
    "            return random.choice(actions)\n",
    "        \n",
    "        hand, action = state.split(\"-\")\n",
    "        cards = [int(card) for card in hand[1:-1].split(\",\")]\n",
    "        action = int(action)\n",
    "        \n",
    "        estimated = random.betavariate(self.parameters[action-1][0], self.parameters[action-1][1])\n",
    "        estimated = 2*n + int(2*(m-n)*estimated)\n",
    "    \n",
    "        if sum(cards) >= estimated: \n",
    "            return int(action)\n",
    "        return 0 \n",
    "        \n",
    "    def update(self, firstHand, secondHand, secondAction): \n",
    "        # State contains the information on your hand, \n",
    "        # what the other played. action is your choice.\n",
    "        if sum(firstHand) > sum(secondHand):\n",
    "            self.parameters[secondAction - 1][0] += 0.5\n",
    "        else:\n",
    "            self.parameters[secondAction - 1][1] += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21840"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstPlayer = ThompsonSampling()\n",
    "secondPlayer = Player()\n",
    "cards = Cards(firstPlayer, secondPlayer)\n",
    "cards.train(it, Thompson = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [10, 10]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 10] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 10] 0\n",
      "-------------------------\n",
      "Current Net Worth: 99-100\n",
      "=========================\n",
      "State:  [7, 11]-6\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 11] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 8] 6\n",
      "-------------------------\n",
      "Current Net Worth: 99-100\n",
      "=========================\n",
      "State:  [9, 11]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 11] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 10] 0\n",
      "-------------------------\n",
      "Current Net Worth: 98-100\n",
      "=========================\n",
      "State:  [9, 10]-7\n",
      "Input your action: 7\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 7\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 10] 7\n",
      "-------------------------\n",
      "Current Net Worth: 98-100\n",
      "=========================\n",
      "State:  [10, 11]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 11] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 8] 5\n",
      "-------------------------\n",
      "Current Net Worth: 93-100\n",
      "=========================\n",
      "State:  [10, 7]-10\n",
      "Input your action: 0\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 7] 0\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 7] 10\n",
      "-------------------------\n",
      "Current Net Worth: 93-99\n",
      "=========================\n",
      "State:  [8, 11]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 11] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 9] 5\n",
      "-------------------------\n",
      "Current Net Worth: 93-94\n",
      "=========================\n",
      "State:  [11, 7]-3\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 7] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 7] 3\n",
      "-------------------------\n",
      "Current Net Worth: 90-94\n",
      "=========================\n",
      "State:  [9, 10]\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 9] 0\n",
      "-------------------------\n",
      "Current Net Worth: 89-94\n",
      "=========================\n",
      "State:  [8, 7]-9\n",
      "Input your action: 9\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 7] 9\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 7] 9\n",
      "-------------------------\n",
      "Current Net Worth: 89-85\n",
      "=========================\n",
      "State:  [9, 9]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 9] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 9] 0\n",
      "-------------------------\n",
      "Current Net Worth: 88-85\n",
      "=========================\n",
      "State:  [9, 8]-5\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 8] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 9] 0\n",
      "-------------------------\n",
      "Current Net Worth: 83-85\n",
      "=========================\n",
      "State:  [9, 7]\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 7] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 10] 0\n",
      "-------------------------\n",
      "Current Net Worth: 82-85\n",
      "=========================\n",
      "State:  [10, 10]-2\n",
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 10] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 11] 2\n",
      "-------------------------\n",
      "Current Net Worth: 82-85\n",
      "=========================\n",
      "State:  [8, 9]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 9] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 9] 0\n",
      "-------------------------\n",
      "Current Net Worth: 81-85\n",
      "=========================\n",
      "State:  [11, 10]-7\n",
      "Input your action: 7\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 10] 7\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 8] 7\n",
      "-------------------------\n",
      "Current Net Worth: 74-85\n",
      "=========================\n",
      "State:  [11, 8]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 8] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 10] 5\n",
      "-------------------------\n",
      "Current Net Worth: 74-80\n",
      "=========================\n",
      "State:  [8, 8]-7\n",
      "Input your action: 7\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 8] 7\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 9] 7\n",
      "-------------------------\n",
      "Current Net Worth: 74-73\n",
      "=========================\n",
      "State:  [8, 9]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 9] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 10] 0\n",
      "-------------------------\n",
      "Current Net Worth: 73-73\n",
      "=========================\n",
      "State:  [10, 9]-8\n",
      "Input your action: 8\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 9] 8\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 7] 8\n",
      "-------------------------\n",
      "Current Net Worth: 65-73\n",
      "=========================\n",
      "State:  [10, 7]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 7] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 8] 0\n",
      "-------------------------\n",
      "Current Net Worth: 64-73\n",
      "=========================\n",
      "State:  [7, 10]-6\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 10] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 11] 6\n",
      "-------------------------\n",
      "Current Net Worth: 64-67\n",
      "=========================\n",
      "State:  [10, 7]\n",
      "Input your action: 4\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 7] 4\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 10] 4\n",
      "-------------------------\n",
      "Current Net Worth: 64-63\n",
      "=========================\n",
      "State:  [9, 11]-8\n",
      "Input your action: 8\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 11] 8\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 8] 8\n",
      "-------------------------\n",
      "Current Net Worth: 56-63\n",
      "=========================\n",
      "State:  [7, 11]\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 11] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 7] 0\n",
      "-------------------------\n",
      "Current Net Worth: 55-63\n",
      "=========================\n",
      "State:  [10, 11]-7\n",
      "Input your action: 7\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 11] 7\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 7] 7\n",
      "-------------------------\n",
      "Current Net Worth: 48-63\n",
      "=========================\n",
      "State:  [7, 9]\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 9] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 7] 0\n",
      "-------------------------\n",
      "Current Net Worth: 47-63\n",
      "=========================\n",
      "State:  [9, 10]-4\n",
      "Input your action: 4\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 4\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 10] 4\n",
      "-------------------------\n",
      "Current Net Worth: 47-59\n",
      "=========================\n",
      "State:  [9, 10]\n",
      "Input your action: 4\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 4\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 10] 0\n",
      "-------------------------\n",
      "Current Net Worth: 46-59\n",
      "=========================\n",
      "State:  [11, 10]-9\n",
      "Input your action: 9\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 10] 9\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 9] 9\n",
      "-------------------------\n",
      "Current Net Worth: 37-59\n",
      "=========================\n",
      "State:  [11, 8]\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 8] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 8] 0\n",
      "-------------------------\n",
      "Current Net Worth: 36-59\n",
      "=========================\n",
      "State:  [11, 10]-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 10] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 9] 2\n",
      "-------------------------\n",
      "Current Net Worth: 34-59\n",
      "=========================\n",
      "State:  [8, 11]\n",
      "Input your action: 5\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 11] 5\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 11] 5\n",
      "-------------------------\n",
      "Current Net Worth: 34-54\n",
      "=========================\n",
      "State:  [10, 10]-2\n",
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 10] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 7] 2\n",
      "-------------------------\n",
      "Current Net Worth: 32-54\n",
      "=========================\n",
      "State:  [7, 8]\n",
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 8] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 11] 2\n",
      "-------------------------\n",
      "Current Net Worth: 32-52\n",
      "=========================\n",
      "State:  [10, 10]-2\n",
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 10] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 7] 2\n",
      "-------------------------\n",
      "Current Net Worth: 30-52\n",
      "=========================\n",
      "State:  [9, 10]\n",
      "Input your action: 8\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 8\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 11] 8\n",
      "-------------------------\n",
      "Current Net Worth: 30-44\n",
      "=========================\n",
      "State:  [9, 7]-4\n",
      "Input your action: 4\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 7] 4\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 7] 4\n",
      "-------------------------\n",
      "Current Net Worth: 26-44\n",
      "=========================\n",
      "State:  [11, 11]\n",
      "Input your action: 8\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 11] 8\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 9] 0\n",
      "-------------------------\n",
      "Current Net Worth: 25-44\n",
      "=========================\n",
      "State:  [8, 10]-9\n",
      "Input your action: 9\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 10] 9\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 10] 9\n",
      "-------------------------\n",
      "Current Net Worth: 16-44\n",
      "=========================\n",
      "State:  [8, 7]\n",
      "Input your action: 3\n",
      "-------------------------\n",
      "The agent hand and last action were: [8, 7] 3\n",
      "-------------------------\n",
      "The adversary hand and last action were: [9, 8] 0\n",
      "-------------------------\n",
      "Current Net Worth: 15-44\n",
      "=========================\n",
      "State:  [9, 11]-6\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 11] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 7] 6\n",
      "-------------------------\n",
      "Current Net Worth: 9-44\n",
      "=========================\n",
      "State:  [10, 9]\n",
      "Input your action: 4\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 9] 4\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 8] 0\n",
      "-------------------------\n",
      "Current Net Worth: 8-44\n",
      "=========================\n",
      "State:  [9, 8]-6\n",
      "Input your action: 6\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 8] 6\n",
      "-------------------------\n",
      "The adversary hand and last action were: [8, 7] 6\n",
      "-------------------------\n",
      "Current Net Worth: 2-44\n",
      "=========================\n",
      "State:  [10, 8]\n",
      "Input your action: 3\n",
      "Try a number in  [1, 2]\n",
      "Input your action: 2\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 8] 2\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 7] 0\n",
      "-------------------------\n",
      "Current Net Worth: 1-44\n",
      "=========================\n",
      "State:  [10, 7]-1\n",
      "Input your action: 1\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 7] 1\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 7] 1\n",
      "-------------------------\n",
      "Current Net Worth: 1-43\n",
      "=========================\n",
      "State:  [10, 7]\n",
      "Input your action: 1\n",
      "-------------------------\n",
      "The agent hand and last action were: [10, 7] 1\n",
      "-------------------------\n",
      "The adversary hand and last action were: [11, 10] 1\n",
      "-------------------------\n",
      "Current Net Worth: 1-42\n",
      "=========================\n",
      "State:  [7, 9]-1\n",
      "Input your action: 1\n",
      "-------------------------\n",
      "The agent hand and last action were: [7, 9] 1\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 11] 1\n",
      "-------------------------\n",
      "Current Net Worth: 1-41\n",
      "=========================\n",
      "State:  [9, 10]\n",
      "Input your action: 1\n",
      "-------------------------\n",
      "The agent hand and last action were: [9, 10] 1\n",
      "-------------------------\n",
      "The adversary hand and last action were: [10, 11] 1\n",
      "-------------------------\n",
      "Current Net Worth: 1-40\n",
      "=========================\n",
      "State:  [11, 8]-1\n",
      "Input your action: 1\n",
      "-------------------------\n",
      "The agent hand and last action were: [11, 8] 1\n",
      "-------------------------\n",
      "The adversary hand and last action were: [7, 7] 1\n",
      "-------------------------\n",
      "Current Net Worth: 0-40\n",
      "=========================\n",
      "\n",
      " ========================= \n",
      " ========================= \n",
      " And the final winner is secondPlayer! :)\n"
     ]
    }
   ],
   "source": [
    "cards = Cards(firstPlayer, HumanPlayer())\n",
    "cards.human(human = True, Thompson = True, result = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
